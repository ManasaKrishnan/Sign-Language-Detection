{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-25T00:36:57.362187Z","iopub.execute_input":"2022-03-25T00:36:57.362465Z","iopub.status.idle":"2022-03-25T00:38:05.43192Z","shell.execute_reply.started":"2022-03-25T00:36:57.362438Z","shell.execute_reply":"2022-03-25T00:38:05.430193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-03-22T02:42:46.100553Z","iopub.execute_input":"2022-03-22T02:42:46.10086Z","iopub.status.idle":"2022-03-22T02:43:21.753696Z","shell.execute_reply.started":"2022-03-22T02:42:46.100827Z","shell.execute_reply":"2022-03-22T02:43:21.75261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\nfrom numpy.random import seed\nimport tensorflow\nseed(1)\ntensorflow.random.set_seed(2)\n\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\n\nfrom glob import glob\nfrom numpy import floor\n\n\n# Plotting sample images from the datastes\n\ndef plot_samples(alphabet):\n    print(\"Samples images for alphabet \" + alphabet)\n    base_path = '/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/'\n    img_path = base_path + alphabet + '/**'\n    path_contents = glob(img_path)\n    \n    plt.figure(figsize=(16,16))\n    imgs = random.sample(path_contents, 4)\n    plt.subplot(151)\n    plt.imshow(cv2.imread(imgs[0]))\n    plt.subplot(152)\n    plt.imshow(cv2.imread(imgs[1]))\n    plt.subplot(153)\n    plt.imshow(cv2.imread(imgs[2]))\n    plt.subplot(154)\n    plt.imshow(cv2.imread(imgs[3]))\n    return\n\nplot_samples('A')","metadata":{"execution":{"iopub.status.busy":"2022-03-25T00:38:52.973231Z","iopub.execute_input":"2022-03-25T00:38:52.973588Z","iopub.status.idle":"2022-03-25T00:39:01.165749Z","shell.execute_reply.started":"2022-03-25T00:38:52.973543Z","shell.execute_reply":"2022-03-25T00:39:01.164327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading datasets and performing data augmentation\n\ntrain_dir = \"../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\ntarget_size = (64, 64)\ntarget_dims = (64, 64, 3) # RGB - 3, BW - 2\nno_classes = 29\nval_split = 0.1\nbatch_size = 64\n \ndata_augmentor = ImageDataGenerator(samplewise_center=True, \n                                    samplewise_std_normalization=True, \n                                    validation_split=val_split)\n\ntrain_generator = data_augmentor.flow_from_directory(train_dir, target_size=target_size, batch_size=batch_size, shuffle=True, subset=\"training\")\nval_generator = data_augmentor.flow_from_directory(train_dir, target_size=target_size, batch_size=batch_size, subset=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2022-03-25T00:39:03.361599Z","iopub.execute_input":"2022-03-25T00:39:03.361944Z","iopub.status.idle":"2022-03-25T00:39:38.532504Z","shell.execute_reply.started":"2022-03-25T00:39:03.361908Z","shell.execute_reply":"2022-03-25T00:39:38.53165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nconv2d_1 = Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=target_dims)\nmodel.add(conv2d_1)\nconv2d_2 = Conv2D(64, kernel_size=4, strides=2, activation='relu')\nmodel.add(conv2d_2)\nmodel.add(Dropout(0.5))\nconv2d_3 = Conv2D(128, kernel_size=4, strides=1, activation='relu')\nmodel.add(conv2d_3)\nconv2d_4 = Conv2D(128, kernel_size=4, strides=2, activation='relu')\nmodel.add(conv2d_4)\nmodel.add(Dropout(0.5))\nconv2d_5 = Conv2D(256, kernel_size=4, strides=1, activation='relu')\nmodel.add(conv2d_5)\nconv2d_6 = Conv2D(256, kernel_size=4, strides=2, activation='relu')\nmodel.add(conv2d_6)\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(no_classes, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-25T00:43:38.113506Z","iopub.execute_input":"2022-03-25T00:43:38.114031Z","iopub.status.idle":"2022-03-25T00:43:38.393709Z","shell.execute_reply.started":"2022-03-25T00:43:38.113978Z","shell.execute_reply":"2022-03-25T00:43:38.392699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-25T00:44:01.373829Z","iopub.execute_input":"2022-03-25T00:44:01.37464Z","iopub.status.idle":"2022-03-25T00:44:01.388168Z","shell.execute_reply.started":"2022-03-25T00:44:01.37459Z","shell.execute_reply":"2022-03-25T00:44:01.387115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model\n\nmodel.fit_generator(train_generator, epochs=5, validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T21:53:01.006246Z","iopub.execute_input":"2022-03-24T21:53:01.006608Z","iopub.status.idle":"2022-03-24T23:45:04.460052Z","shell.execute_reply.started":"2022-03-24T21:53:01.00657Z","shell.execute_reply":"2022-03-24T23:45:04.459062Z"},"trusted":true},"execution_count":null,"outputs":[]}]}