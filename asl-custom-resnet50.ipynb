{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**IMPORTING LIBRARIES AND INITIALIZING DIRECTORIES**","metadata":{}},{"cell_type":"code","source":"# Import Keras libraries and packages\nfrom keras.applications.resnet import ResNet50\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport cv2\n\ntrain_dir = \"../input/american-sign-language-dataset/dataset/train\" \ntest_dir = \"../input/american-sign-language-dataset/dataset/test\"","metadata":{"execution":{"iopub.status.busy":"2022-05-05T21:23:47.019235Z","iopub.execute_input":"2022-05-05T21:23:47.019629Z","iopub.status.idle":"2022-05-05T21:23:53.206547Z","shell.execute_reply.started":"2022-05-05T21:23:47.019599Z","shell.execute_reply":"2022-05-05T21:23:53.205464Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Display first image from every class\nfig = plt.figure(figsize=(14, 14))\nuniq_labels = sorted((f for f in os.listdir(train_dir) if not f.startswith(\".\")))\nfor idx, label in enumerate(uniq_labels):\n    filepath = train_dir + \"/\" + label + \"/\" + label + \"2.jpg\"\n    image = cv2.imread(filepath)\n    image = cv2.resize(cv2.imread(filepath), (128, 128))\n    ax = fig.add_subplot(5, 8, idx+1, xticks=[], yticks=[])\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.savefig('dataset.png')\n    plt.imshow(image)\n    ax.set_title('Class: %s'%label)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T21:23:53.210689Z","iopub.execute_input":"2022-05-05T21:23:53.210943Z","iopub.status.idle":"2022-05-05T21:24:08.212018Z","shell.execute_reply.started":"2022-05-05T21:23:53.210914Z","shell.execute_reply":"2022-05-05T21:24:08.211176Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(rescale=1./255, \n                               validation_split=0.2) \ntrain = train_gen.flow_from_directory(train_dir, target_size=(128, 128), subset=\"training\", batch_size=32, class_mode='categorical')\nval = train_gen.flow_from_directory(train_dir, target_size=(128, 128), subset=\"validation\", batch_size=32, class_mode='categorical')\ntest_gen = ImageDataGenerator(rescale=1./255)\ntest = test_gen.flow_from_directory(test_dir, target_size=(128, 128), class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T21:24:13.250957Z","iopub.execute_input":"2022-05-05T21:24:13.253024Z","iopub.status.idle":"2022-05-05T21:24:19.091273Z","shell.execute_reply.started":"2022-05-05T21:24:13.252983Z","shell.execute_reply":"2022-05-05T21:24:19.090243Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# **RESNET50 MODEL**","metadata":{}},{"cell_type":"code","source":"classifier_resnet = ResNet50(input_shape=(128, 128, 3), include_top=False, weights='imagenet')","metadata":{"id":"Qh5g_XDnK8zz","outputId":"c957afe2-d327-488c-9706-a85a41e48d1b","execution":{"iopub.status.busy":"2022-05-05T21:24:19.093332Z","iopub.execute_input":"2022-05-05T21:24:19.093649Z","iopub.status.idle":"2022-05-05T21:24:21.551240Z","shell.execute_reply.started":"2022-05-05T21:24:19.093607Z","shell.execute_reply":"2022-05-05T21:24:21.550344Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Not training existing weights for resnet50\nfor layer in classifier_resnet.layers:\n    layer.trainable = False","metadata":{"id":"ZkOGLAxbT1qC","execution":{"iopub.status.busy":"2022-05-05T21:24:21.553963Z","iopub.execute_input":"2022-05-05T21:24:21.554668Z","iopub.status.idle":"2022-05-05T21:24:21.565894Z","shell.execute_reply.started":"2022-05-05T21:24:21.554615Z","shell.execute_reply":"2022-05-05T21:24:21.565068Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"len(test.class_indices.keys())","metadata":{"execution":{"iopub.status.busy":"2022-05-05T21:24:21.567648Z","iopub.execute_input":"2022-05-05T21:24:21.567870Z","iopub.status.idle":"2022-05-05T21:24:21.581345Z","shell.execute_reply.started":"2022-05-05T21:24:21.567842Z","shell.execute_reply":"2022-05-05T21:24:21.580627Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"classifier = classifier_resnet.output\nclassifier = Flatten()(classifier)\nclassifier = Dropout(0.2)(classifier)\nclassifier = Dense(units=38, activation='softmax')(classifier)\n\nmodel = Model(inputs = classifier_resnet.input , outputs = classifier)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"W5bF3Iw0T8Nw","execution":{"iopub.status.busy":"2022-05-05T21:24:21.583125Z","iopub.execute_input":"2022-05-05T21:24:21.583447Z","iopub.status.idle":"2022-05-05T21:24:21.636248Z","shell.execute_reply.started":"2022-05-05T21:24:21.583389Z","shell.execute_reply":"2022-05-05T21:24:21.635424Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"3k9BSlD3T8Gu","execution":{"iopub.status.busy":"2022-05-05T21:24:32.693914Z","iopub.execute_input":"2022-05-05T21:24:32.694870Z","iopub.status.idle":"2022-05-05T21:24:32.796682Z","shell.execute_reply.started":"2022-05-05T21:24:32.694801Z","shell.execute_reply":"2022-05-05T21:24:32.795850Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"resnet_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights = True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, min_lr=0.000002)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T21:26:24.467864Z","iopub.execute_input":"2022-05-05T21:26:24.468197Z","iopub.status.idle":"2022-05-05T21:26:24.475724Z","shell.execute_reply.started":"2022-05-05T21:26:24.468159Z","shell.execute_reply":"2022-05-05T21:26:24.473375Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Fit the model\nhistory = model.fit(train, validation_data = val, epochs = 10, batch_size = 32, shuffle = True, verbose = 1, \n                    callbacks = [resnet_early_stopping,reduce_lr])","metadata":{"id":"YjsavcC3UPlC","execution":{"iopub.status.busy":"2022-05-05T21:26:27.966176Z","iopub.execute_input":"2022-05-05T21:26:27.966492Z","iopub.status.idle":"2022-05-06T00:19:07.651610Z","shell.execute_reply.started":"2022-05-05T21:26:27.966459Z","shell.execute_reply":"2022-05-06T00:19:07.650093Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Saving the current model of resnet\nmodel.save('/kaggle/working/resnet50_model_final.h5')","metadata":{"id":"tRGl1dYcT7_b","execution":{"iopub.status.busy":"2022-05-06T00:20:28.982300Z","iopub.execute_input":"2022-05-06T00:20:28.982774Z","iopub.status.idle":"2022-05-06T00:20:29.575084Z","shell.execute_reply.started":"2022-05-06T00:20:28.982699Z","shell.execute_reply":"2022-05-06T00:20:29.574339Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# from keras.models import load_model\n# model = load_model('/kaggle/working/resnet50_model1.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(test, verbose = 0)\nprint('Accuracy for test images:', round(score[1] * 100, 3), '%')\n\nscore = model.evaluate(val, verbose = 0)\nprint('Accuracy for validation images:', round(score[1] * 100, 3), '%')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:32:44.726090Z","iopub.execute_input":"2022-05-06T00:32:44.726387Z","iopub.status.idle":"2022-05-06T00:39:32.806383Z","shell.execute_reply.started":"2022-05-06T00:32:44.726354Z","shell.execute_reply":"2022-05-06T00:39:32.805521Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy curve for Resnet50')\nplt.ylabel('Accuracy')\nplt.xlabel('Number of epochs')\nplt.legend(['train', 'validation'], loc='lower right')\nplt.savefig('accuracy_resnet50.png')\nplt.show()\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss curve for Resnet50')\nplt.ylabel('Loss')\nplt.xlabel('Number of epochs')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.savefig('loss_resnet50.png')\nplt.show()","metadata":{"id":"KLJ3WqwmUbuE","execution":{"iopub.status.busy":"2022-05-06T00:43:20.965274Z","iopub.execute_input":"2022-05-06T00:43:20.965596Z","iopub.status.idle":"2022-05-06T00:43:21.467910Z","shell.execute_reply.started":"2022-05-06T00:43:20.965559Z","shell.execute_reply":"2022-05-06T00:43:21.467341Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y, y_pred):\n    cm = confusion_matrix(y, y_pred)\n    plt.figure(figsize = (18, 18))\n    ax = plt.subplot()\n    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n    plt.colorbar()\n    plt.title(\"Confusion Matrix\")\n    tick_marks = np.arange(len(uniq_labels))\n    plt.xticks(tick_marks, uniq_labels, rotation=45)\n    plt.yticks(tick_marks, uniq_labels)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    ax.title.set_fontsize(20)\n    ax.xaxis.label.set_fontsize(16)\n    ax.yaxis.label.set_fontsize(16)\n    limit = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n    plt.savefig('confusionmatrix_resnet50.png')\n    plt.show()","metadata":{"id":"aB8iM1s3Ubmy","execution":{"iopub.status.busy":"2022-05-06T00:57:29.932244Z","iopub.execute_input":"2022-05-06T00:57:29.932555Z","iopub.status.idle":"2022-05-06T00:57:29.944484Z","shell.execute_reply.started":"2022-05-06T00:57:29.932521Z","shell.execute_reply":"2022-05-06T00:57:29.943747Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"true_value = []\nresnet_pred = []\n    \nuniq_labels = sorted((f for f in os.listdir(train_dir) if not f.startswith(\".\")))\nfor idx, label in enumerate(uniq_labels):\n    for file in [f for f in os.listdir(test_dir + \"/\" + label) if not f.startswith(\".\")]:\n        true_value.append(test.class_indices[label])\n        filepath = test_dir + \"/\" + label + \"/\" + file\n        image = cv2.resize(cv2.imread(filepath), (128, 128))\n        image_normalized = image / 255\n            \n        #resnet50\n        resnet_50_image_prediction = np.argmax(model.predict(np.array([image_normalized])))\n        resnet_pred.append(resnet_50_image_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:57:31.650252Z","iopub.execute_input":"2022-05-06T00:57:31.650535Z","iopub.status.idle":"2022-05-06T01:12:32.974970Z","shell.execute_reply.started":"2022-05-06T00:57:31.650504Z","shell.execute_reply":"2022-05-06T01:12:32.974143Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport itertools\n\n# Confusion matrix for test data\nplot_confusion_matrix(true_value, resnet_pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T01:12:32.976884Z","iopub.execute_input":"2022-05-06T01:12:32.977383Z","iopub.status.idle":"2022-05-06T01:12:40.621291Z","shell.execute_reply.started":"2022-05-06T01:12:32.977334Z","shell.execute_reply":"2022-05-06T01:12:40.620379Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"classes = test.class_indices.keys()\nprint(classification_report(true_value, resnet_pred, target_names = list(classes)))","metadata":{"execution":{"iopub.status.busy":"2022-05-06T01:24:20.901634Z","iopub.execute_input":"2022-05-06T01:24:20.901975Z","iopub.status.idle":"2022-05-06T01:24:20.929509Z","shell.execute_reply.started":"2022-05-06T01:24:20.901941Z","shell.execute_reply":"2022-05-06T01:24:20.928932Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(\"Input label to be predicted from one of these (1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, BEST OF LUCK, C, D, E, F, G, H, I, I LOVE YOU, J, K, L, \\\nM, N, O, P, Q, R, S, SPACE, T, U, V, W, X, Y, Z)\")\ntrue_label = input().upper()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T01:30:59.923885Z","iopub.execute_input":"2022-05-06T01:30:59.924274Z","iopub.status.idle":"2022-05-06T01:31:04.904906Z","shell.execute_reply.started":"2022-05-06T01:30:59.924235Z","shell.execute_reply":"2022-05-06T01:31:04.904285Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# For only one prediction\nclass_labels = {0: '1', 1:'2', 2:'3', 3:'4', 4:'5', 5: '6', 6:'7', 7:'8', 8:'9', 9: 'A', 10:'B', 11:'BEST OF LUCK', 12:'C', 13:'D', 14: 'E', 15:'F', 16:'G', \n                17:'H', 18:'I', 19:'I LOVE YOU', 20:'J', 21:'K', 22:'L', 23:'M', 24:'N', 25:'O', 26:'P', 27: 'Q', 28:'R', 29:'S', 30:'SPACE', \n                31:'T', 32:'U', 33:'V', 34:'W', 35: 'X', 36:'Y', 37:'Z'}\nfilepath = filepath = test_dir + \"/\" + true_label + \"/\" + true_label + \"1001.jpg\"\nimg = cv2.resize(cv2.imread(filepath), (128,128))\n# img = cv2.resize(cv2.imread('../input/american-sign-language-dataset/dataset/test/' +true_label+ '/' + true_label + '1100.jpg'),(128,128))\nimg_normalized = img/255\nresnet_50_image_prediction = np.argmax(model.predict(np.array([img_normalized])))\nplt.title(f\"Prediction Class = {class_labels[resnet_50_image_prediction]}\\n True Class = {true_label}\")\nplt.imshow(img)\n\nif resnet_50_image_prediction in class_labels.keys():\n    prediction = class_labels[resnet_50_image_prediction]\nelse:\n    prediction = \"Not Found\"","metadata":{"id":"BZYEjMzyUzuF","execution":{"iopub.status.busy":"2022-05-06T01:31:06.285215Z","iopub.execute_input":"2022-05-06T01:31:06.285923Z","iopub.status.idle":"2022-05-06T01:31:06.654449Z","shell.execute_reply.started":"2022-05-06T01:31:06.285889Z","shell.execute_reply":"2022-05-06T01:31:06.653864Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}